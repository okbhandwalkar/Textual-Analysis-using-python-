{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60bbfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Travel and Tourism Outlook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/travel-and-tourism-outlook/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057f2899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The UN projects a 20-30% decline in international tourist arrivals in 2020. This could put up to 50 million jobs at risk, with Asia likely to be the most affected continent. But will the good old days of tourism and travel return next year? What is changing? Read on to discover what our robot, Athena, has found on the future of this topic and act accordingly for you, your family and organization in the years ahead. Make notes on issues that could affect you and them as you go. If you are new to foresight, we recommend you view this slide presentation first to get the best out of this report Speed read Athena’s high-level take-outs on the left of each slide, or delve deeper into her findings on the right. Analysis For a more detailed explanation of the graphics used in this presentation please click here. All outlooks based on the time period 2020-2070 and what’s likely to be happening in 2025 at a 95% confidence level unless otherwise stated. Please contact us for longer-term outlooks. VIDEO SUMMARY To read more and for a video summary, click here \n",
      " The UN projects a 2030 decline in international tourist arrivals in 2020 This could put up to 50 million jobs at risk with Asia likely to be the most affected continent But will the good old days of tourism and travel return next year What is changing Read on to discover what our robot Athena has found on the future of this topic and act accordingly for you your family and organization in the years ahead Make notes on issues that could affect you and them as you go If you are new to foresight we recommend you view this slide presentation first to get the best out of this report Speed read Athena’s highlevel takeouts on the left of each slide or delve deeper into her findings on the right Analysis For a more detailed explanation of the graphics used in this presentation please click here All outlooks based on the time period 20202070 and what’s likely to be happening in 2025 at a 95 confidence level unless otherwise stated Please contact us for longerterm outlooks VIDEO SUMMARY To read more and for a video summary click here \n",
      "['The', 'UN', 'projects', 'a', '2030', 'decline', 'in', 'international', 'tourist', 'arrivals', 'in', '2020', 'This', 'could', 'put', 'up', 'to', '50', 'million', 'jobs', 'at', 'risk', 'with', 'Asia', 'likely', 'to', 'be', 'the', 'most', 'affected', 'continent', 'But', 'will', 'the', 'good', 'old', 'days', 'of', 'tourism', 'and', 'travel', 'return', 'next', 'year', 'What', 'is', 'changing', 'Read', 'on', 'to', 'discover', 'what', 'our', 'robot', 'Athena', 'has', 'found', 'on', 'the', 'future', 'of', 'this', 'topic', 'and', 'act', 'accordingly', 'for', 'you', 'your', 'family', 'and', 'organization', 'in', 'the', 'years', 'ahead', 'Make', 'notes', 'on', 'issues', 'that', 'could', 'affect', 'you', 'and', 'them', 'as', 'you', 'go', 'If', 'you', 'are', 'new', 'to', 'foresight', 'we', 'recommend', 'you', 'view', 'this', 'slide', 'presentation', 'first', 'to', 'get', 'the', 'best', 'out', 'of', 'this', 'report', 'Speed', 'read', 'Athena’s', 'highlevel', 'takeouts', 'on', 'the', 'left', 'of', 'each', 'slide', 'or', 'delve', 'deeper', 'into', 'her', 'findings', 'on', 'the', 'right', 'Analysis', 'For', 'a', 'more', 'detailed', 'explanation', 'of', 'the', 'graphics', 'used', 'in', 'this', 'presentation', 'please', 'click', 'here', 'All', 'outlooks', 'based', 'on', 'the', 'time', 'period', '20202070', 'and', 'what’s', 'likely', 'to', 'be', 'happening', 'in', '2025', 'at', 'a', '95', 'confidence', 'level', 'unless', 'otherwise', 'stated', 'Please', 'contact', 'us', 'for', 'longerterm', 'outlooks', 'VIDEO', 'SUMMARY', 'To', 'read', 'more', 'and', 'for', 'a', 'video', 'summary', 'click', 'here']\n"
     ]
    }
   ],
   "source": [
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "print(content)\n",
    "text = content.split()\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7da24fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea71c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5089ea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c23d5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/travel-and-to...</td>\n",
       "      <td>Travel and Tourism Outlook</td>\n",
       "      <td>The UN projects a 2030 decline in internation...</td>\n",
       "      <td>The UN projects a 2030 decline in internationa...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.273255</td>\n",
       "      <td>0.424912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/travel-and-to...   \n",
       "\n",
       "                        title  \\\n",
       "0  Travel and Tourism Outlook   \n",
       "\n",
       "                                             content  \\\n",
       "0   The UN projects a 2030 decline in internation...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  The UN projects a 2030 decline in internationa...               6   \n",
       "\n",
       "   Negative_Score  polarity  subjectivity  \n",
       "0               3  0.273255      0.424912  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "\n",
    "# Adding Subjectivity & Polarity\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54198f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word average = 855.0\n",
      "FOG INDEX =  78.56\n",
      "Average no of words per sentence\n",
      "189.0\n",
      "Complex Words 293\n"
     ]
    }
   ],
   "source": [
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=print(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ae447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count 1041\n",
      "Percentage of Complex Words 28.14601344860711\n",
      "Average Word per Length 4.523809523809524\n",
      "The AVG number of syllables in the word is: \n",
      "1.8306878306878307\n",
      "Word Count 1041\n",
      "Percentage of Complex Words 28.14601344860711\n",
      "Average Word per Length 4.523809523809524\n",
      "The AVG number of syllables in the word is: \n",
      "1.8306878306878307\n"
     ]
    }
   ],
   "source": [
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625915a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "Word average = 855.0\n",
      "FOG INDEX =  78.56\n",
      "Average no of words per sentence\n",
      "189.0\n",
      "Complex Words 293\n",
      "Word Count 1041\n",
      "Percentage of Complex Words 28.14601344860711\n",
      "Average Word per Length 4.523809523809524\n",
      "The AVG number of syllables in the word is: \n",
      "1.8306878306878307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Word</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORDS</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>syllable</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/travel-and-to...</td>\n",
       "      <td>Travel and Tourism Outlook</td>\n",
       "      <td>The UN projects a 2030 decline in internation...</td>\n",
       "      <td>The UN projects a 2030 decline in internationa...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>855.0</td>\n",
       "      <td>28.146013</td>\n",
       "      <td>78.56</td>\n",
       "      <td>189.0</td>\n",
       "      <td>293</td>\n",
       "      <td>1041</td>\n",
       "      <td>1.830688</td>\n",
       "      <td>4.52381</td>\n",
       "      <td>0.273255</td>\n",
       "      <td>0.424912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/travel-and-to...   \n",
       "\n",
       "                        title  \\\n",
       "0  Travel and Tourism Outlook   \n",
       "\n",
       "                                             content  \\\n",
       "0   The UN projects a 2030 decline in internation...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  The UN projects a 2030 decline in internationa...               6   \n",
       "\n",
       "   Negative_Score  Avg_Sentence_Length  Percentage_Complex_Word  Fog_Index  \\\n",
       "0               3                855.0                28.146013      78.56   \n",
       "\n",
       "    AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORDS  Word_Count  syllable  \\\n",
       "0                              189.0            293        1041  1.830688   \n",
       "\n",
       "   Average_Word_Length  polarity  subjectivity  \n",
       "0              4.52381  0.273255      0.424912  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/travel-and-tourism-outlook/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "# title\n",
    "\n",
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "# print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "# print(content)\n",
    "text = content.split()\n",
    "# print(text)\n",
    "len(text)\n",
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)\n",
    "\n",
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)\n",
    "\n",
    "\n",
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data\n",
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "print(AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n",
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "syllable = (syllable_count/len(content.split()))\n",
    "print(syllable)\n",
    "\n",
    "data = [[url,title,content,filter_content,Positive_score,Negative_score,AVG_SENTENCE_LENGTH,pcw,FOG_INDEX,\n",
    "         AVG_NUMBER_OF_WORDS_PER_SENTENCE,COMPLEX_WORDS,Word_Count,syllable,Average_Word_Length]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\",\"Avg_Sentence_Length\"\n",
    "                               ,\"Percentage_Complex_Word\",\"Fog_Index\",\" AVG_NUMBER_OF_WORDS_PER_SENTENCE\",\"COMPLEX_WORDS\",\n",
    "                               \"Word_Count\",\"syllable\",\"Average_Word_Length\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6121482",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\Om Bhandwalkar\\Desktop\\BlackCoffer Assignment\\Output\\url_101.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8a014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
