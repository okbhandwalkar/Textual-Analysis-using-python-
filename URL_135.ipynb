{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049601cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Should people wear fabric gloves? Seeking evidence regarding the differential transfer of COVID-19 (or coronaviruses generally) between surfaces?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/should-people-wear-fabric-gloves-seeking-evidence-regarding-the-differential-transfer-of-covid-19-or-coronaviruses-generally-between-surfaces/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba395296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is there any evidence about whether fabric or bare hands would spread covid-19 more from one surface to another? (e.g. opening a door using a fabric glove). Assuming the fabric doesn’t touch your face, like bare hands easily do, even with efforts to remember not to people struggle to remember. I’ve been thinking of prompts to prevent face touching, such as wearing fabric gloves when out and about, but I don’t want to promote this unless the fabric is at-least-no-worse than hands for transferring the virus between surfaces. I’m talking about use in the community for instance when people have to travel or go to food shops, not in a healthcare context. The gloves should be changed between different settings (e.g. apartment block, bus, shop – switch to a new pair of gloves for each). The gloves should be ironed hot at the end of each day. As far as I can tell from my attempts searching, this is evidence-based, but I’m keen to know from someone who is better at interpreting evidence in this field if it is sensible.  Use fabric gloves to avoid spreading of Coronavirus from outside every person going out for daily work touching every were using these gloves before entering the house remove the glove outside the home and clean hand with sanitizer to kill the virus.  Use of this glove to wash with sanitizer and bowling in water about 60 to 70c is put outside the home for drying in night time morning these gloves are used. Any time you go outside and come back come do this is the better way to avoid spreading of Coronavirus.  Well, the risk of conducting covid19 by using gloves or not the same but the gloves remember us not to touch our eyes, mouth, and nose so don’t get infection properly if you contact an infected patient, at that time wearing gloves become a must. \n",
      " Is there any evidence about whether fabric or bare hands would spread covid19 more from one surface to another eg opening a door using a fabric glove Assuming the fabric doesn’t touch your face like bare hands easily do even with efforts to remember not to people struggle to remember I’ve been thinking of prompts to prevent face touching such as wearing fabric gloves when out and about but I don’t want to promote this unless the fabric is atleastnoworse than hands for transferring the virus between surfaces I’m talking about use in the community for instance when people have to travel or go to food shops not in a healthcare context The gloves should be changed between different settings eg apartment block bus shop – switch to a new pair of gloves for each The gloves should be ironed hot at the end of each day As far as I can tell from my attempts searching this is evidencebased but I’m keen to know from someone who is better at interpreting evidence in this field if it is sensible  Use fabric gloves to avoid spreading of Coronavirus from outside every person going out for daily work touching every were using these gloves before entering the house remove the glove outside the home and clean hand with sanitizer to kill the virus  Use of this glove to wash with sanitizer and bowling in water about 60 to 70c is put outside the home for drying in night time morning these gloves are used Any time you go outside and come back come do this is the better way to avoid spreading of Coronavirus  Well the risk of conducting covid19 by using gloves or not the same but the gloves remember us not to touch our eyes mouth and nose so don’t get infection properly if you contact an infected patient at that time wearing gloves become a must \n",
      "['Is', 'there', 'any', 'evidence', 'about', 'whether', 'fabric', 'or', 'bare', 'hands', 'would', 'spread', 'covid19', 'more', 'from', 'one', 'surface', 'to', 'another', 'eg', 'opening', 'a', 'door', 'using', 'a', 'fabric', 'glove', 'Assuming', 'the', 'fabric', 'doesn’t', 'touch', 'your', 'face', 'like', 'bare', 'hands', 'easily', 'do', 'even', 'with', 'efforts', 'to', 'remember', 'not', 'to', 'people', 'struggle', 'to', 'remember', 'I’ve', 'been', 'thinking', 'of', 'prompts', 'to', 'prevent', 'face', 'touching', 'such', 'as', 'wearing', 'fabric', 'gloves', 'when', 'out', 'and', 'about', 'but', 'I', 'don’t', 'want', 'to', 'promote', 'this', 'unless', 'the', 'fabric', 'is', 'atleastnoworse', 'than', 'hands', 'for', 'transferring', 'the', 'virus', 'between', 'surfaces', 'I’m', 'talking', 'about', 'use', 'in', 'the', 'community', 'for', 'instance', 'when', 'people', 'have', 'to', 'travel', 'or', 'go', 'to', 'food', 'shops', 'not', 'in', 'a', 'healthcare', 'context', 'The', 'gloves', 'should', 'be', 'changed', 'between', 'different', 'settings', 'eg', 'apartment', 'block', 'bus', 'shop', '–', 'switch', 'to', 'a', 'new', 'pair', 'of', 'gloves', 'for', 'each', 'The', 'gloves', 'should', 'be', 'ironed', 'hot', 'at', 'the', 'end', 'of', 'each', 'day', 'As', 'far', 'as', 'I', 'can', 'tell', 'from', 'my', 'attempts', 'searching', 'this', 'is', 'evidencebased', 'but', 'I’m', 'keen', 'to', 'know', 'from', 'someone', 'who', 'is', 'better', 'at', 'interpreting', 'evidence', 'in', 'this', 'field', 'if', 'it', 'is', 'sensible', 'Use', 'fabric', 'gloves', 'to', 'avoid', 'spreading', 'of', 'Coronavirus', 'from', 'outside', 'every', 'person', 'going', 'out', 'for', 'daily', 'work', 'touching', 'every', 'were', 'using', 'these', 'gloves', 'before', 'entering', 'the', 'house', 'remove', 'the', 'glove', 'outside', 'the', 'home', 'and', 'clean', 'hand', 'with', 'sanitizer', 'to', 'kill', 'the', 'virus', 'Use', 'of', 'this', 'glove', 'to', 'wash', 'with', 'sanitizer', 'and', 'bowling', 'in', 'water', 'about', '60', 'to', '70c', 'is', 'put', 'outside', 'the', 'home', 'for', 'drying', 'in', 'night', 'time', 'morning', 'these', 'gloves', 'are', 'used', 'Any', 'time', 'you', 'go', 'outside', 'and', 'come', 'back', 'come', 'do', 'this', 'is', 'the', 'better', 'way', 'to', 'avoid', 'spreading', 'of', 'Coronavirus', 'Well', 'the', 'risk', 'of', 'conducting', 'covid19', 'by', 'using', 'gloves', 'or', 'not', 'the', 'same', 'but', 'the', 'gloves', 'remember', 'us', 'not', 'to', 'touch', 'our', 'eyes', 'mouth', 'and', 'nose', 'so', 'don’t', 'get', 'infection', 'properly', 'if', 'you', 'contact', 'an', 'infected', 'patient', 'at', 'that', 'time', 'wearing', 'gloves', 'become', 'a', 'must']\n"
     ]
    }
   ],
   "source": [
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "print(content)\n",
    "text = content.split()\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f329d40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c29272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf502cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb6ebb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/should-people...</td>\n",
       "      <td>Should people wear fabric gloves? Seeking evid...</td>\n",
       "      <td>Is there any evidence about whether fabric or...</td>\n",
       "      <td>Is there any evidence about whether fabric or ...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.176653</td>\n",
       "      <td>0.366494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/should-people...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Should people wear fabric gloves? Seeking evid...   \n",
       "\n",
       "                                             content  \\\n",
       "0   Is there any evidence about whether fabric or...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  Is there any evidence about whether fabric or ...              10   \n",
       "\n",
       "   Negative_Score  polarity  subjectivity  \n",
       "0               7  0.176653      0.366494  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "\n",
    "# Adding Subjectivity & Polarity\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148d3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word average = 1430.0\n",
      "FOG INDEX =  128.69\n",
      "Average no of words per sentence\n",
      "318.0\n",
      "Complex Words 509\n"
     ]
    }
   ],
   "source": [
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=print(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "145b4c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count 1751\n",
      "Percentage of Complex Words 29.06910336950314\n",
      "Average Word per Length 4.49685534591195\n",
      "The AVG number of syllables in the word is: \n",
      "1.7924528301886793\n",
      "Word Count 1751\n",
      "Percentage of Complex Words 29.06910336950314\n",
      "Average Word per Length 4.49685534591195\n",
      "The AVG number of syllables in the word is: \n",
      "1.7924528301886793\n"
     ]
    }
   ],
   "source": [
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec023b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "7\n",
      "Word average = 1547.0\n",
      "FOG INDEX =  137.72\n",
      "Average no of words per sentence\n",
      "340.0\n",
      "Complex Words 542\n",
      "Word Count 1891\n",
      "Percentage of Complex Words 28.662083553675306\n",
      "Average Word per Length 4.55\n",
      "The AVG number of syllables in the word is: \n",
      "1.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Word</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORDS</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>syllable</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/should-people...</td>\n",
       "      <td>Should people wear fabric gloves? Seeking evid...</td>\n",
       "      <td>People wearing protective masks walk at Hong ...</td>\n",
       "      <td>People wearing protective masks walk at Hong K...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>28.662084</td>\n",
       "      <td>137.72</td>\n",
       "      <td>340.0</td>\n",
       "      <td>542</td>\n",
       "      <td>1891</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.176653</td>\n",
       "      <td>0.366494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/should-people...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Should people wear fabric gloves? Seeking evid...   \n",
       "\n",
       "                                             content  \\\n",
       "0   People wearing protective masks walk at Hong ...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  People wearing protective masks walk at Hong K...              11   \n",
       "\n",
       "   Negative_Score  Avg_Sentence_Length  Percentage_Complex_Word  Fog_Index  \\\n",
       "0               7               1547.0                28.662084     137.72   \n",
       "\n",
       "    AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORDS  Word_Count  syllable  \\\n",
       "0                              340.0            542        1891       1.8   \n",
       "\n",
       "   Average_Word_Length  polarity  subjectivity  \n",
       "0                 4.55  0.176653      0.366494  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/should-people-wear-fabric-gloves-seeking-evidence-regarding-the-differential-transfer-of-covid-19-or-coronaviruses-generally-between-surfaces/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "# title\n",
    "\n",
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "# print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "# print(content)\n",
    "text = content.split()\n",
    "# print(text)\n",
    "len(text)\n",
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)\n",
    "\n",
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)\n",
    "\n",
    "\n",
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data\n",
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "print(AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n",
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "syllable = (syllable_count/len(content.split()))\n",
    "print(syllable)\n",
    "\n",
    "data = [[url,title,content,filter_content,Positive_score,Negative_score,AVG_SENTENCE_LENGTH,pcw,FOG_INDEX,\n",
    "         AVG_NUMBER_OF_WORDS_PER_SENTENCE,COMPLEX_WORDS,Word_Count,syllable,Average_Word_Length]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\",\"Avg_Sentence_Length\"\n",
    "                               ,\"Percentage_Complex_Word\",\"Fog_Index\",\" AVG_NUMBER_OF_WORDS_PER_SENTENCE\",\"COMPLEX_WORDS\",\n",
    "                               \"Word_Count\",\"syllable\",\"Average_Word_Length\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b6cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\Om Bhandwalkar\\Desktop\\BlackCoffer Assignment\\Output\\url_135.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59808600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
