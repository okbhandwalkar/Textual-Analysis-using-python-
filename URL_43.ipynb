{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce7ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c074b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"\"\"https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9caa54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c152a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47a643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How humans and machines are evolving to work together?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec1a6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In future or in upcoming years humans and machines are going to work together in every field of work. In upcoming days machines will be the need for every human being. Machines [AI technology] will do the work which humans are incapable of doing. Machines will partner and co-operate with humans. According to the professor at the university of Washington, he explained that, as a result of AI, there will be more demand for existing jobs and new jobs will be created that are unimaginable today. Human workers and machines will work together flawlessly, complementing each other. Machines will learn to carry out easier tasks such as following processes or crunching data. They will also help the humans while difficult. Machines or AI will create a great job opportunities for humans in future. John Kelly ll, executive vice president of IBM once said that “Man and Machines working together always beat or make a better decision than a man or a machine independently.” \\xa0In future, the three sectors of our country like agriculture sector, industrial sector and service sector are going to utilize the machines. So, that their work becomes not difficult. As of now, we can only see that for agriculture purposes various kinds of machines are used which we called as a modern farming method. Some major technologies [machines] that are harvest automation, autonomous tractors, seeding, and weeing and drones. As a result, farms can do agriculture peacefully. In the industrial sector also humans and machines are working together to increase production. Various types of machines are used in industries such as packing machines, loading machine etc. humans provide instructions to the machines and maintain the management in the company. Soon robots [machines] will assist doctors with surgeries. For instance, a doctor at remote location could direct a surgical robot to perform an open heart surgery. But the approaches option and decision will be left to experience and wisdom of the doctor not the robot. What do you think of machines if they will make humans less or more in the field? Machines will push human professionals up the skillset ladder into uniquely human skills such as creativity, social abilities, empathy, and sense-making, which machines cannot automate. As a result, machines will make the workplace more, not less for humans. However, humans have to learn new skills throughout their lives. It is said that in the future 80% of process-oriented tasks will be done by machines. Quantitative reasoning tasks will be done approximately 50% by humans and 50% by machines, while humans will continue to do more than 80% of cross-functional reasoning tasks. According to Harvard research machines, algorithms can read diagnostic scans with 92% accuracy. Humans can do it with 96% accuracy. Together, it will be 99% accurate. Human-machine collaboration enables companies to interact with employees and customers in the novel, more effective ways. Smart machines are helping humans to expand their abilities in three ways. They can amplify our cognitive strengths; interact with customers and employees to free us from higher-level tasks, and embody human skills to extend our physical capabilities. In the research, it was found that 1,500 companies achieve the most significant performance improvement when humans and machines work together. New machine systems have beyond-human cognitive abilities, which many of us fear could potentially dehumanize the future of work. Machines will indeed automate most repetitive and physical tasks, and part of quantitative tasks such as programming and even data science. According to D.E Shaw Group and professor at the University of Washington, explained that, as a result of machines, there will be more demand for existing jobs, and new jobs will be created that are unimaginable today. This is similar to how we couldn’t imagine a web app developer decades ago, and now millions make a living doing that today. Machines are good at doing tasks with speed, precision, and accuracy. But machines are not very good at responding to unknown situations or making judgments. That part will be left to humans. Hence, the need for both humans and machines will be there in the future. Humans and machines have divergent skill sets that, when combined can transform the way we work. Machines have already infiltrated every aspect of our lives, and we must learn to live with them. In the future, human workers will interact more closely with humans.\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Blackcoffer Insights 29: Vachika Sharma, ANAND ENGLISH MEDIUM SCHOOL \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4855f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In future or in upcoming years humans and machines are going to work together in every field of work In upcoming days machines will be the need for every human being Machines AI technology will do the work which humans are incapable of doing Machines will partner and cooperate with humans According to the professor at the university of Washington he explained that as a result of AI there will be more demand for existing jobs and new jobs will be created that are unimaginable today Human workers and machines will work together flawlessly complementing each other Machines will learn to carry out easier tasks such as following processes or crunching data They will also help the humans while difficult Machines or AI will create a great job opportunities for humans in future John Kelly ll executive vice president of IBM once said that “Man and Machines working together always beat or make a better decision than a man or a machine independently” \\xa0In future the three sectors of our country like agriculture sector industrial sector and service sector are going to utilize the machines So that their work becomes not difficult As of now we can only see that for agriculture purposes various kinds of machines are used which we called as a modern farming method Some major technologies machines that are harvest automation autonomous tractors seeding and weeing and drones As a result farms can do agriculture peacefully In the industrial sector also humans and machines are working together to increase production Various types of machines are used in industries such as packing machines loading machine etc humans provide instructions to the machines and maintain the management in the company Soon robots machines will assist doctors with surgeries For instance a doctor at remote location could direct a surgical robot to perform an open heart surgery But the approaches option and decision will be left to experience and wisdom of the doctor not the robot What do you think of machines if they will make humans less or more in the field Machines will push human professionals up the skillset ladder into uniquely human skills such as creativity social abilities empathy and sensemaking which machines cannot automate As a result machines will make the workplace more not less for humans However humans have to learn new skills throughout their lives It is said that in the future 80 of processoriented tasks will be done by machines Quantitative reasoning tasks will be done approximately 50 by humans and 50 by machines while humans will continue to do more than 80 of crossfunctional reasoning tasks According to Harvard research machines algorithms can read diagnostic scans with 92 accuracy Humans can do it with 96 accuracy Together it will be 99 accurate Humanmachine collaboration enables companies to interact with employees and customers in the novel more effective ways Smart machines are helping humans to expand their abilities in three ways They can amplify our cognitive strengths interact with customers and employees to free us from higherlevel tasks and embody human skills to extend our physical capabilities In the research it was found that 1500 companies achieve the most significant performance improvement when humans and machines work together New machine systems have beyondhuman cognitive abilities which many of us fear could potentially dehumanize the future of work Machines will indeed automate most repetitive and physical tasks and part of quantitative tasks such as programming and even data science According to DE Shaw Group and professor at the University of Washington explained that as a result of machines there will be more demand for existing jobs and new jobs will be created that are unimaginable today This is similar to how we couldn’t imagine a web app developer decades ago and now millions make a living doing that today Machines are good at doing tasks with speed precision and accuracy But machines are not very good at responding to unknown situations or making judgments That part will be left to humans Hence the need for both humans and machines will be there in the future Humans and machines have divergent skill sets that when combined can transform the way we work Machines have already infiltrated every aspect of our lives and we must learn to live with them In the future human workers will interact more closely with humans\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Blackcoffer Insights 29 Vachika Sharma ANAND ENGLISH MEDIUM SCHOOL \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff79fcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'future',\n",
       " 'or',\n",
       " 'in',\n",
       " 'upcoming',\n",
       " 'years',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'work',\n",
       " 'together',\n",
       " 'in',\n",
       " 'every',\n",
       " 'field',\n",
       " 'of',\n",
       " 'work',\n",
       " 'In',\n",
       " 'upcoming',\n",
       " 'days',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'every',\n",
       " 'human',\n",
       " 'being',\n",
       " 'Machines',\n",
       " 'AI',\n",
       " 'technology',\n",
       " 'will',\n",
       " 'do',\n",
       " 'the',\n",
       " 'work',\n",
       " 'which',\n",
       " 'humans',\n",
       " 'are',\n",
       " 'incapable',\n",
       " 'of',\n",
       " 'doing',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'partner',\n",
       " 'and',\n",
       " 'cooperate',\n",
       " 'with',\n",
       " 'humans',\n",
       " 'According',\n",
       " 'to',\n",
       " 'the',\n",
       " 'professor',\n",
       " 'at',\n",
       " 'the',\n",
       " 'university',\n",
       " 'of',\n",
       " 'Washington',\n",
       " 'he',\n",
       " 'explained',\n",
       " 'that',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'more',\n",
       " 'demand',\n",
       " 'for',\n",
       " 'existing',\n",
       " 'jobs',\n",
       " 'and',\n",
       " 'new',\n",
       " 'jobs',\n",
       " 'will',\n",
       " 'be',\n",
       " 'created',\n",
       " 'that',\n",
       " 'are',\n",
       " 'unimaginable',\n",
       " 'today',\n",
       " 'Human',\n",
       " 'workers',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'work',\n",
       " 'together',\n",
       " 'flawlessly',\n",
       " 'complementing',\n",
       " 'each',\n",
       " 'other',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'easier',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'following',\n",
       " 'processes',\n",
       " 'or',\n",
       " 'crunching',\n",
       " 'data',\n",
       " 'They',\n",
       " 'will',\n",
       " 'also',\n",
       " 'help',\n",
       " 'the',\n",
       " 'humans',\n",
       " 'while',\n",
       " 'difficult',\n",
       " 'Machines',\n",
       " 'or',\n",
       " 'AI',\n",
       " 'will',\n",
       " 'create',\n",
       " 'a',\n",
       " 'great',\n",
       " 'job',\n",
       " 'opportunities',\n",
       " 'for',\n",
       " 'humans',\n",
       " 'in',\n",
       " 'future',\n",
       " 'John',\n",
       " 'Kelly',\n",
       " 'll',\n",
       " 'executive',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'of',\n",
       " 'IBM',\n",
       " 'once',\n",
       " 'said',\n",
       " 'that',\n",
       " '“Man',\n",
       " 'and',\n",
       " 'Machines',\n",
       " 'working',\n",
       " 'together',\n",
       " 'always',\n",
       " 'beat',\n",
       " 'or',\n",
       " 'make',\n",
       " 'a',\n",
       " 'better',\n",
       " 'decision',\n",
       " 'than',\n",
       " 'a',\n",
       " 'man',\n",
       " 'or',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'independently”',\n",
       " 'In',\n",
       " 'future',\n",
       " 'the',\n",
       " 'three',\n",
       " 'sectors',\n",
       " 'of',\n",
       " 'our',\n",
       " 'country',\n",
       " 'like',\n",
       " 'agriculture',\n",
       " 'sector',\n",
       " 'industrial',\n",
       " 'sector',\n",
       " 'and',\n",
       " 'service',\n",
       " 'sector',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'utilize',\n",
       " 'the',\n",
       " 'machines',\n",
       " 'So',\n",
       " 'that',\n",
       " 'their',\n",
       " 'work',\n",
       " 'becomes',\n",
       " 'not',\n",
       " 'difficult',\n",
       " 'As',\n",
       " 'of',\n",
       " 'now',\n",
       " 'we',\n",
       " 'can',\n",
       " 'only',\n",
       " 'see',\n",
       " 'that',\n",
       " 'for',\n",
       " 'agriculture',\n",
       " 'purposes',\n",
       " 'various',\n",
       " 'kinds',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'used',\n",
       " 'which',\n",
       " 'we',\n",
       " 'called',\n",
       " 'as',\n",
       " 'a',\n",
       " 'modern',\n",
       " 'farming',\n",
       " 'method',\n",
       " 'Some',\n",
       " 'major',\n",
       " 'technologies',\n",
       " 'machines',\n",
       " 'that',\n",
       " 'are',\n",
       " 'harvest',\n",
       " 'automation',\n",
       " 'autonomous',\n",
       " 'tractors',\n",
       " 'seeding',\n",
       " 'and',\n",
       " 'weeing',\n",
       " 'and',\n",
       " 'drones',\n",
       " 'As',\n",
       " 'a',\n",
       " 'result',\n",
       " 'farms',\n",
       " 'can',\n",
       " 'do',\n",
       " 'agriculture',\n",
       " 'peacefully',\n",
       " 'In',\n",
       " 'the',\n",
       " 'industrial',\n",
       " 'sector',\n",
       " 'also',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'working',\n",
       " 'together',\n",
       " 'to',\n",
       " 'increase',\n",
       " 'production',\n",
       " 'Various',\n",
       " 'types',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'industries',\n",
       " 'such',\n",
       " 'as',\n",
       " 'packing',\n",
       " 'machines',\n",
       " 'loading',\n",
       " 'machine',\n",
       " 'etc',\n",
       " 'humans',\n",
       " 'provide',\n",
       " 'instructions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'machines',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'the',\n",
       " 'management',\n",
       " 'in',\n",
       " 'the',\n",
       " 'company',\n",
       " 'Soon',\n",
       " 'robots',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'assist',\n",
       " 'doctors',\n",
       " 'with',\n",
       " 'surgeries',\n",
       " 'For',\n",
       " 'instance',\n",
       " 'a',\n",
       " 'doctor',\n",
       " 'at',\n",
       " 'remote',\n",
       " 'location',\n",
       " 'could',\n",
       " 'direct',\n",
       " 'a',\n",
       " 'surgical',\n",
       " 'robot',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'an',\n",
       " 'open',\n",
       " 'heart',\n",
       " 'surgery',\n",
       " 'But',\n",
       " 'the',\n",
       " 'approaches',\n",
       " 'option',\n",
       " 'and',\n",
       " 'decision',\n",
       " 'will',\n",
       " 'be',\n",
       " 'left',\n",
       " 'to',\n",
       " 'experience',\n",
       " 'and',\n",
       " 'wisdom',\n",
       " 'of',\n",
       " 'the',\n",
       " 'doctor',\n",
       " 'not',\n",
       " 'the',\n",
       " 'robot',\n",
       " 'What',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'if',\n",
       " 'they',\n",
       " 'will',\n",
       " 'make',\n",
       " 'humans',\n",
       " 'less',\n",
       " 'or',\n",
       " 'more',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'push',\n",
       " 'human',\n",
       " 'professionals',\n",
       " 'up',\n",
       " 'the',\n",
       " 'skillset',\n",
       " 'ladder',\n",
       " 'into',\n",
       " 'uniquely',\n",
       " 'human',\n",
       " 'skills',\n",
       " 'such',\n",
       " 'as',\n",
       " 'creativity',\n",
       " 'social',\n",
       " 'abilities',\n",
       " 'empathy',\n",
       " 'and',\n",
       " 'sensemaking',\n",
       " 'which',\n",
       " 'machines',\n",
       " 'cannot',\n",
       " 'automate',\n",
       " 'As',\n",
       " 'a',\n",
       " 'result',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'make',\n",
       " 'the',\n",
       " 'workplace',\n",
       " 'more',\n",
       " 'not',\n",
       " 'less',\n",
       " 'for',\n",
       " 'humans',\n",
       " 'However',\n",
       " 'humans',\n",
       " 'have',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'new',\n",
       " 'skills',\n",
       " 'throughout',\n",
       " 'their',\n",
       " 'lives',\n",
       " 'It',\n",
       " 'is',\n",
       " 'said',\n",
       " 'that',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " '80',\n",
       " 'of',\n",
       " 'processoriented',\n",
       " 'tasks',\n",
       " 'will',\n",
       " 'be',\n",
       " 'done',\n",
       " 'by',\n",
       " 'machines',\n",
       " 'Quantitative',\n",
       " 'reasoning',\n",
       " 'tasks',\n",
       " 'will',\n",
       " 'be',\n",
       " 'done',\n",
       " 'approximately',\n",
       " '50',\n",
       " 'by',\n",
       " 'humans',\n",
       " 'and',\n",
       " '50',\n",
       " 'by',\n",
       " 'machines',\n",
       " 'while',\n",
       " 'humans',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'do',\n",
       " 'more',\n",
       " 'than',\n",
       " '80',\n",
       " 'of',\n",
       " 'crossfunctional',\n",
       " 'reasoning',\n",
       " 'tasks',\n",
       " 'According',\n",
       " 'to',\n",
       " 'Harvard',\n",
       " 'research',\n",
       " 'machines',\n",
       " 'algorithms',\n",
       " 'can',\n",
       " 'read',\n",
       " 'diagnostic',\n",
       " 'scans',\n",
       " 'with',\n",
       " '92',\n",
       " 'accuracy',\n",
       " 'Humans',\n",
       " 'can',\n",
       " 'do',\n",
       " 'it',\n",
       " 'with',\n",
       " '96',\n",
       " 'accuracy',\n",
       " 'Together',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " '99',\n",
       " 'accurate',\n",
       " 'Humanmachine',\n",
       " 'collaboration',\n",
       " 'enables',\n",
       " 'companies',\n",
       " 'to',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'employees',\n",
       " 'and',\n",
       " 'customers',\n",
       " 'in',\n",
       " 'the',\n",
       " 'novel',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'ways',\n",
       " 'Smart',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'helping',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'expand',\n",
       " 'their',\n",
       " 'abilities',\n",
       " 'in',\n",
       " 'three',\n",
       " 'ways',\n",
       " 'They',\n",
       " 'can',\n",
       " 'amplify',\n",
       " 'our',\n",
       " 'cognitive',\n",
       " 'strengths',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'customers',\n",
       " 'and',\n",
       " 'employees',\n",
       " 'to',\n",
       " 'free',\n",
       " 'us',\n",
       " 'from',\n",
       " 'higherlevel',\n",
       " 'tasks',\n",
       " 'and',\n",
       " 'embody',\n",
       " 'human',\n",
       " 'skills',\n",
       " 'to',\n",
       " 'extend',\n",
       " 'our',\n",
       " 'physical',\n",
       " 'capabilities',\n",
       " 'In',\n",
       " 'the',\n",
       " 'research',\n",
       " 'it',\n",
       " 'was',\n",
       " 'found',\n",
       " 'that',\n",
       " '1500',\n",
       " 'companies',\n",
       " 'achieve',\n",
       " 'the',\n",
       " 'most',\n",
       " 'significant',\n",
       " 'performance',\n",
       " 'improvement',\n",
       " 'when',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'work',\n",
       " 'together',\n",
       " 'New',\n",
       " 'machine',\n",
       " 'systems',\n",
       " 'have',\n",
       " 'beyondhuman',\n",
       " 'cognitive',\n",
       " 'abilities',\n",
       " 'which',\n",
       " 'many',\n",
       " 'of',\n",
       " 'us',\n",
       " 'fear',\n",
       " 'could',\n",
       " 'potentially',\n",
       " 'dehumanize',\n",
       " 'the',\n",
       " 'future',\n",
       " 'of',\n",
       " 'work',\n",
       " 'Machines',\n",
       " 'will',\n",
       " 'indeed',\n",
       " 'automate',\n",
       " 'most',\n",
       " 'repetitive',\n",
       " 'and',\n",
       " 'physical',\n",
       " 'tasks',\n",
       " 'and',\n",
       " 'part',\n",
       " 'of',\n",
       " 'quantitative',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'programming',\n",
       " 'and',\n",
       " 'even',\n",
       " 'data',\n",
       " 'science',\n",
       " 'According',\n",
       " 'to',\n",
       " 'DE',\n",
       " 'Shaw',\n",
       " 'Group',\n",
       " 'and',\n",
       " 'professor',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Washington',\n",
       " 'explained',\n",
       " 'that',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'of',\n",
       " 'machines',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'more',\n",
       " 'demand',\n",
       " 'for',\n",
       " 'existing',\n",
       " 'jobs',\n",
       " 'and',\n",
       " 'new',\n",
       " 'jobs',\n",
       " 'will',\n",
       " 'be',\n",
       " 'created',\n",
       " 'that',\n",
       " 'are',\n",
       " 'unimaginable',\n",
       " 'today',\n",
       " 'This',\n",
       " 'is',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'how',\n",
       " 'we',\n",
       " 'couldn’t',\n",
       " 'imagine',\n",
       " 'a',\n",
       " 'web',\n",
       " 'app',\n",
       " 'developer',\n",
       " 'decades',\n",
       " 'ago',\n",
       " 'and',\n",
       " 'now',\n",
       " 'millions',\n",
       " 'make',\n",
       " 'a',\n",
       " 'living',\n",
       " 'doing',\n",
       " 'that',\n",
       " 'today',\n",
       " 'Machines',\n",
       " 'are',\n",
       " 'good',\n",
       " 'at',\n",
       " 'doing',\n",
       " 'tasks',\n",
       " 'with',\n",
       " 'speed',\n",
       " 'precision',\n",
       " 'and',\n",
       " 'accuracy',\n",
       " 'But',\n",
       " 'machines',\n",
       " 'are',\n",
       " 'not',\n",
       " 'very',\n",
       " 'good',\n",
       " 'at',\n",
       " 'responding',\n",
       " 'to',\n",
       " 'unknown',\n",
       " 'situations',\n",
       " 'or',\n",
       " 'making',\n",
       " 'judgments',\n",
       " 'That',\n",
       " 'part',\n",
       " 'will',\n",
       " 'be',\n",
       " 'left',\n",
       " 'to',\n",
       " 'humans',\n",
       " 'Hence',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'both',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'will',\n",
       " 'be',\n",
       " 'there',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " 'Humans',\n",
       " 'and',\n",
       " 'machines',\n",
       " 'have',\n",
       " 'divergent',\n",
       " 'skill',\n",
       " 'sets',\n",
       " 'that',\n",
       " 'when',\n",
       " 'combined',\n",
       " 'can',\n",
       " 'transform',\n",
       " 'the',\n",
       " 'way',\n",
       " 'we',\n",
       " 'work',\n",
       " 'Machines',\n",
       " 'have',\n",
       " 'already',\n",
       " 'infiltrated',\n",
       " 'every',\n",
       " 'aspect',\n",
       " 'of',\n",
       " 'our',\n",
       " 'lives',\n",
       " 'and',\n",
       " 'we',\n",
       " 'must',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'live',\n",
       " 'with',\n",
       " 'them',\n",
       " 'In',\n",
       " 'the',\n",
       " 'future',\n",
       " 'human',\n",
       " 'workers',\n",
       " 'will',\n",
       " 'interact',\n",
       " 'more',\n",
       " 'closely',\n",
       " 'with',\n",
       " 'humans',\n",
       " 'Blackcoffer',\n",
       " 'Insights',\n",
       " '29',\n",
       " 'Vachika',\n",
       " 'Sharma',\n",
       " 'ANAND',\n",
       " 'ENGLISH',\n",
       " 'MEDIUM',\n",
       " 'SCHOOL']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = content.split()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaffbac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e019954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ee09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "519476f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d958f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965f106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a7ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ff7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_content = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b87908a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c281bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa49b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c06b47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/in-future-or-...</td>\n",
       "      <td>How humans and machines are evolving to work t...</td>\n",
       "      <td>In future or in upcoming years humans and mac...</td>\n",
       "      <td>In future or in upcoming years humans and mach...</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.146947</td>\n",
       "      <td>0.416908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/in-future-or-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  How humans and machines are evolving to work t...   \n",
       "\n",
       "                                             content  \\\n",
       "0   In future or in upcoming years humans and mac...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  In future or in upcoming years humans and mach...              27   \n",
       "\n",
       "   Negative_Score  polarity  subjectivity  \n",
       "0              12  0.146947      0.416908  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "\n",
    "# Adding Subjectivity & Polarity\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f77ffa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word average = 3754.0\n"
     ]
    }
   ],
   "source": [
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf1cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8a38bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298.35\n"
     ]
    }
   ],
   "source": [
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(FOG_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45840405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735.0\n"
     ]
    }
   ],
   "source": [
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=print(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeadba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325\n"
     ]
    }
   ],
   "source": [
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(COMPLEX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e791f3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4491\n"
     ]
    }
   ],
   "source": [
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(Word_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c1d645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50345134713872\n"
     ]
    }
   ],
   "source": [
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(pcw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf9b8de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.107482993197279\n"
     ]
    }
   ],
   "source": [
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(Average_Word_Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5389ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AVG number of syllables in the word is: \n",
      "1.997278911564626\n"
     ]
    }
   ],
   "source": [
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c067cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "12\n",
      "Word average = 3754.0\n",
      "FOG INDEX =  298.35\n",
      "Average no of words per sentence\n",
      "735.0\n",
      "Complex Words 1325\n",
      "Word Count 4491\n",
      "Percentage of Complex Words 29.50345134713872\n",
      "Average Word per Length 5.107482993197279\n",
      "The AVG number of syllables in the word is: \n",
      "1.997278911564626\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Word</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORDS</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>syllable</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/in-future-or-...</td>\n",
       "      <td>How humans and machines are evolving to work t...</td>\n",
       "      <td>In future or in upcoming years humans and mac...</td>\n",
       "      <td>In future or in upcoming years humans and mach...</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>29.503451</td>\n",
       "      <td>298.35</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1325</td>\n",
       "      <td>4491</td>\n",
       "      <td>1.997279</td>\n",
       "      <td>5.107483</td>\n",
       "      <td>0.146947</td>\n",
       "      <td>0.416908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/in-future-or-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  How humans and machines are evolving to work t...   \n",
       "\n",
       "                                             content  \\\n",
       "0   In future or in upcoming years humans and mac...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  In future or in upcoming years humans and mach...              27   \n",
       "\n",
       "   Negative_Score  Avg_Sentence_Length  Percentage_Complex_Word  Fog_Index  \\\n",
       "0              12               3754.0                29.503451     298.35   \n",
       "\n",
       "    AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORDS  Word_Count  syllable  \\\n",
       "0                              735.0           1325        4491  1.997279   \n",
       "\n",
       "   Average_Word_Length  polarity  subjectivity  \n",
       "0             5.107483  0.146947      0.416908  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "# title\n",
    "\n",
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "# print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "# print(content)\n",
    "text = content.split()\n",
    "# print(text)\n",
    "len(text)\n",
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)\n",
    "\n",
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)\n",
    "\n",
    "\n",
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data\n",
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "print(AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n",
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "syllable = (syllable_count/len(content.split()))\n",
    "print(syllable)\n",
    "\n",
    "data = [[url,title,content,filter_content,Positive_score,Negative_score,AVG_SENTENCE_LENGTH,pcw,FOG_INDEX,\n",
    "         AVG_NUMBER_OF_WORDS_PER_SENTENCE,COMPLEX_WORDS,Word_Count,syllable,Average_Word_Length]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\",\"Avg_Sentence_Length\"\n",
    "                               ,\"Percentage_Complex_Word\",\"Fog_Index\",\" AVG_NUMBER_OF_WORDS_PER_SENTENCE\",\"COMPLEX_WORDS\",\n",
    "                               \"Word_Count\",\"syllable\",\"Average_Word_Length\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca4f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\Om Bhandwalkar\\Desktop\\BlackCoffer Assignment\\Output\\url_43.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10c9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
