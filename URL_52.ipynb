{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5efcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acddeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"\"\"https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d402da44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How machine learning used in finance and banking?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368fd694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Through AI tools like natural language processing, Alexa and google assistant has led the retail industry in its rise towards conversational commerce. As if a customer was interacting with a clerk in a retail store, conversational commerce makes it possible for users to engage with software to research, purchase, or get customer assistance with products and services across a wide range of industries. With Alexa, for example, users can\\xa0ask any Alexa-enabled device\\xa0to add an item to an Amazon shopping cart, set a purchasing reminder when a product is running low, or carry out a complete purchase without having to access a shopping cart. The result is a seamless conversational experience that enables consumers to carry out transactions as quickly as it takes to speak a sentence. Through AI tools like natural language processing, Alexa has led the retail industry in its rise towards conversational commerce. As if a customer was interacting with a clerk in a retail store, conversational commerce makes it possible for users to engage with software to research, purchase, or get customer assistance with products and services across a wide range of industries. With the advent of personalized products and on-call delivery, customers have come to expect a new standard experience: fast, easy, accurate, and personalized. Accomplishing this\\xa0without sacrificing your workday can be\\xa0a challenge, since the data processing required to meet these needs is immense. Luckily,\\xa0virtual agents (VAs), powered by conversational AI,\\xa0can utilize this information faster and more accurately than humans, finding insights and automating communication to deliver an enriched customer experience. If you invest based on these improvements, you’ll find that implementing these tools delivers a powerful competitive advantage. AI has helped in automobile, education, retail and commerce, finance and banking and healthcare. Voice AI\\xa0has powered the wheels of conversational e-commerce, which has impacted the way the customer communicates with the brand in multiple industries. Brands generally build a campaign to emotionally connect with customers, for long-term growth. With Voice, brand campaigns need to be short and ones that can lead to immediate buying. Conversational e-commerce is still in its nascent stage and it is expected to grow manifold in the coming years. The future of shopping is going to Voice AI and marketers have to get on the bandwagon fast to increase their brand value and visibility. Targeting will have to be highly personalized for success.  Despite its narrow focus, conversation AI is an extremely lucrative technology for enterprises, helping businesses more profitable. While an AI chatbot is the most popular form of conversational AI, there are still many other use cases across the enterprise.\\xa0 While an exclusively chat- or voice-based shopping experience for all scenarios may never completely replace the in-person experience, conversational commerce will continue to grow as an added method of convenient and efficient communication. As users continue to become more accustomed to engaging with chatbots and voice-driven interfaces, expect more innovations in the space as brands continue to develop their unique conversation-based solutions. Blackcoffer Insights 28: Samyak Jain  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2271d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Through AI tools like natural language processing Alexa and google assistant has led the retail industry in its rise towards conversational commerce As if a customer was interacting with a clerk in a retail store conversational commerce makes it possible for users to engage with software to research purchase or get customer assistance with products and services across a wide range of industries With Alexa for example users can\\xa0ask any Alexaenabled device\\xa0to add an item to an Amazon shopping cart set a purchasing reminder when a product is running low or carry out a complete purchase without having to access a shopping cart The result is a seamless conversational experience that enables consumers to carry out transactions as quickly as it takes to speak a sentence Through AI tools like natural language processing Alexa has led the retail industry in its rise towards conversational commerce As if a customer was interacting with a clerk in a retail store conversational commerce makes it possible for users to engage with software to research purchase or get customer assistance with products and services across a wide range of industries With the advent of personalized products and oncall delivery customers have come to expect a new standard experience fast easy accurate and personalized Accomplishing this\\xa0without sacrificing your workday can be\\xa0a challenge since the data processing required to meet these needs is immense Luckily\\xa0virtual agents VAs powered by conversational AI\\xa0can utilize this information faster and more accurately than humans finding insights and automating communication to deliver an enriched customer experience If you invest based on these improvements you’ll find that implementing these tools delivers a powerful competitive advantage AI has helped in automobile education retail and commerce finance and banking and healthcare Voice AI\\xa0has powered the wheels of conversational ecommerce which has impacted the way the customer communicates with the brand in multiple industries Brands generally build a campaign to emotionally connect with customers for longterm growth With Voice brand campaigns need to be short and ones that can lead to immediate buying Conversational ecommerce is still in its nascent stage and it is expected to grow manifold in the coming years The future of shopping is going to Voice AI and marketers have to get on the bandwagon fast to increase their brand value and visibility Targeting will have to be highly personalized for success  Despite its narrow focus conversation AI is an extremely lucrative technology for enterprises helping businesses more profitable While an AI chatbot is the most popular form of conversational AI there are still many other use cases across the enterprise\\xa0 While an exclusively chat or voicebased shopping experience for all scenarios may never completely replace the inperson experience conversational commerce will continue to grow as an added method of convenient and efficient communication As users continue to become more accustomed to engaging with chatbots and voicedriven interfaces expect more innovations in the space as brands continue to develop their unique conversationbased solutions Blackcoffer Insights 28 Samyak Jain  '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77618d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Through',\n",
       " 'AI',\n",
       " 'tools',\n",
       " 'like',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'Alexa',\n",
       " 'and',\n",
       " 'google',\n",
       " 'assistant',\n",
       " 'has',\n",
       " 'led',\n",
       " 'the',\n",
       " 'retail',\n",
       " 'industry',\n",
       " 'in',\n",
       " 'its',\n",
       " 'rise',\n",
       " 'towards',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'As',\n",
       " 'if',\n",
       " 'a',\n",
       " 'customer',\n",
       " 'was',\n",
       " 'interacting',\n",
       " 'with',\n",
       " 'a',\n",
       " 'clerk',\n",
       " 'in',\n",
       " 'a',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'makes',\n",
       " 'it',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'users',\n",
       " 'to',\n",
       " 'engage',\n",
       " 'with',\n",
       " 'software',\n",
       " 'to',\n",
       " 'research',\n",
       " 'purchase',\n",
       " 'or',\n",
       " 'get',\n",
       " 'customer',\n",
       " 'assistance',\n",
       " 'with',\n",
       " 'products',\n",
       " 'and',\n",
       " 'services',\n",
       " 'across',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'industries',\n",
       " 'With',\n",
       " 'Alexa',\n",
       " 'for',\n",
       " 'example',\n",
       " 'users',\n",
       " 'can',\n",
       " 'ask',\n",
       " 'any',\n",
       " 'Alexaenabled',\n",
       " 'device',\n",
       " 'to',\n",
       " 'add',\n",
       " 'an',\n",
       " 'item',\n",
       " 'to',\n",
       " 'an',\n",
       " 'Amazon',\n",
       " 'shopping',\n",
       " 'cart',\n",
       " 'set',\n",
       " 'a',\n",
       " 'purchasing',\n",
       " 'reminder',\n",
       " 'when',\n",
       " 'a',\n",
       " 'product',\n",
       " 'is',\n",
       " 'running',\n",
       " 'low',\n",
       " 'or',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'a',\n",
       " 'complete',\n",
       " 'purchase',\n",
       " 'without',\n",
       " 'having',\n",
       " 'to',\n",
       " 'access',\n",
       " 'a',\n",
       " 'shopping',\n",
       " 'cart',\n",
       " 'The',\n",
       " 'result',\n",
       " 'is',\n",
       " 'a',\n",
       " 'seamless',\n",
       " 'conversational',\n",
       " 'experience',\n",
       " 'that',\n",
       " 'enables',\n",
       " 'consumers',\n",
       " 'to',\n",
       " 'carry',\n",
       " 'out',\n",
       " 'transactions',\n",
       " 'as',\n",
       " 'quickly',\n",
       " 'as',\n",
       " 'it',\n",
       " 'takes',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'a',\n",
       " 'sentence',\n",
       " 'Through',\n",
       " 'AI',\n",
       " 'tools',\n",
       " 'like',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'Alexa',\n",
       " 'has',\n",
       " 'led',\n",
       " 'the',\n",
       " 'retail',\n",
       " 'industry',\n",
       " 'in',\n",
       " 'its',\n",
       " 'rise',\n",
       " 'towards',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'As',\n",
       " 'if',\n",
       " 'a',\n",
       " 'customer',\n",
       " 'was',\n",
       " 'interacting',\n",
       " 'with',\n",
       " 'a',\n",
       " 'clerk',\n",
       " 'in',\n",
       " 'a',\n",
       " 'retail',\n",
       " 'store',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'makes',\n",
       " 'it',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'users',\n",
       " 'to',\n",
       " 'engage',\n",
       " 'with',\n",
       " 'software',\n",
       " 'to',\n",
       " 'research',\n",
       " 'purchase',\n",
       " 'or',\n",
       " 'get',\n",
       " 'customer',\n",
       " 'assistance',\n",
       " 'with',\n",
       " 'products',\n",
       " 'and',\n",
       " 'services',\n",
       " 'across',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'industries',\n",
       " 'With',\n",
       " 'the',\n",
       " 'advent',\n",
       " 'of',\n",
       " 'personalized',\n",
       " 'products',\n",
       " 'and',\n",
       " 'oncall',\n",
       " 'delivery',\n",
       " 'customers',\n",
       " 'have',\n",
       " 'come',\n",
       " 'to',\n",
       " 'expect',\n",
       " 'a',\n",
       " 'new',\n",
       " 'standard',\n",
       " 'experience',\n",
       " 'fast',\n",
       " 'easy',\n",
       " 'accurate',\n",
       " 'and',\n",
       " 'personalized',\n",
       " 'Accomplishing',\n",
       " 'this',\n",
       " 'without',\n",
       " 'sacrificing',\n",
       " 'your',\n",
       " 'workday',\n",
       " 'can',\n",
       " 'be',\n",
       " 'a',\n",
       " 'challenge',\n",
       " 'since',\n",
       " 'the',\n",
       " 'data',\n",
       " 'processing',\n",
       " 'required',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'these',\n",
       " 'needs',\n",
       " 'is',\n",
       " 'immense',\n",
       " 'Luckily',\n",
       " 'virtual',\n",
       " 'agents',\n",
       " 'VAs',\n",
       " 'powered',\n",
       " 'by',\n",
       " 'conversational',\n",
       " 'AI',\n",
       " 'can',\n",
       " 'utilize',\n",
       " 'this',\n",
       " 'information',\n",
       " 'faster',\n",
       " 'and',\n",
       " 'more',\n",
       " 'accurately',\n",
       " 'than',\n",
       " 'humans',\n",
       " 'finding',\n",
       " 'insights',\n",
       " 'and',\n",
       " 'automating',\n",
       " 'communication',\n",
       " 'to',\n",
       " 'deliver',\n",
       " 'an',\n",
       " 'enriched',\n",
       " 'customer',\n",
       " 'experience',\n",
       " 'If',\n",
       " 'you',\n",
       " 'invest',\n",
       " 'based',\n",
       " 'on',\n",
       " 'these',\n",
       " 'improvements',\n",
       " 'you’ll',\n",
       " 'find',\n",
       " 'that',\n",
       " 'implementing',\n",
       " 'these',\n",
       " 'tools',\n",
       " 'delivers',\n",
       " 'a',\n",
       " 'powerful',\n",
       " 'competitive',\n",
       " 'advantage',\n",
       " 'AI',\n",
       " 'has',\n",
       " 'helped',\n",
       " 'in',\n",
       " 'automobile',\n",
       " 'education',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'commerce',\n",
       " 'finance',\n",
       " 'and',\n",
       " 'banking',\n",
       " 'and',\n",
       " 'healthcare',\n",
       " 'Voice',\n",
       " 'AI',\n",
       " 'has',\n",
       " 'powered',\n",
       " 'the',\n",
       " 'wheels',\n",
       " 'of',\n",
       " 'conversational',\n",
       " 'ecommerce',\n",
       " 'which',\n",
       " 'has',\n",
       " 'impacted',\n",
       " 'the',\n",
       " 'way',\n",
       " 'the',\n",
       " 'customer',\n",
       " 'communicates',\n",
       " 'with',\n",
       " 'the',\n",
       " 'brand',\n",
       " 'in',\n",
       " 'multiple',\n",
       " 'industries',\n",
       " 'Brands',\n",
       " 'generally',\n",
       " 'build',\n",
       " 'a',\n",
       " 'campaign',\n",
       " 'to',\n",
       " 'emotionally',\n",
       " 'connect',\n",
       " 'with',\n",
       " 'customers',\n",
       " 'for',\n",
       " 'longterm',\n",
       " 'growth',\n",
       " 'With',\n",
       " 'Voice',\n",
       " 'brand',\n",
       " 'campaigns',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'short',\n",
       " 'and',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'can',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'immediate',\n",
       " 'buying',\n",
       " 'Conversational',\n",
       " 'ecommerce',\n",
       " 'is',\n",
       " 'still',\n",
       " 'in',\n",
       " 'its',\n",
       " 'nascent',\n",
       " 'stage',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'expected',\n",
       " 'to',\n",
       " 'grow',\n",
       " 'manifold',\n",
       " 'in',\n",
       " 'the',\n",
       " 'coming',\n",
       " 'years',\n",
       " 'The',\n",
       " 'future',\n",
       " 'of',\n",
       " 'shopping',\n",
       " 'is',\n",
       " 'going',\n",
       " 'to',\n",
       " 'Voice',\n",
       " 'AI',\n",
       " 'and',\n",
       " 'marketers',\n",
       " 'have',\n",
       " 'to',\n",
       " 'get',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bandwagon',\n",
       " 'fast',\n",
       " 'to',\n",
       " 'increase',\n",
       " 'their',\n",
       " 'brand',\n",
       " 'value',\n",
       " 'and',\n",
       " 'visibility',\n",
       " 'Targeting',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'highly',\n",
       " 'personalized',\n",
       " 'for',\n",
       " 'success',\n",
       " 'Despite',\n",
       " 'its',\n",
       " 'narrow',\n",
       " 'focus',\n",
       " 'conversation',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'an',\n",
       " 'extremely',\n",
       " 'lucrative',\n",
       " 'technology',\n",
       " 'for',\n",
       " 'enterprises',\n",
       " 'helping',\n",
       " 'businesses',\n",
       " 'more',\n",
       " 'profitable',\n",
       " 'While',\n",
       " 'an',\n",
       " 'AI',\n",
       " 'chatbot',\n",
       " 'is',\n",
       " 'the',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'form',\n",
       " 'of',\n",
       " 'conversational',\n",
       " 'AI',\n",
       " 'there',\n",
       " 'are',\n",
       " 'still',\n",
       " 'many',\n",
       " 'other',\n",
       " 'use',\n",
       " 'cases',\n",
       " 'across',\n",
       " 'the',\n",
       " 'enterprise',\n",
       " 'While',\n",
       " 'an',\n",
       " 'exclusively',\n",
       " 'chat',\n",
       " 'or',\n",
       " 'voicebased',\n",
       " 'shopping',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'all',\n",
       " 'scenarios',\n",
       " 'may',\n",
       " 'never',\n",
       " 'completely',\n",
       " 'replace',\n",
       " 'the',\n",
       " 'inperson',\n",
       " 'experience',\n",
       " 'conversational',\n",
       " 'commerce',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'grow',\n",
       " 'as',\n",
       " 'an',\n",
       " 'added',\n",
       " 'method',\n",
       " 'of',\n",
       " 'convenient',\n",
       " 'and',\n",
       " 'efficient',\n",
       " 'communication',\n",
       " 'As',\n",
       " 'users',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'become',\n",
       " 'more',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'engaging',\n",
       " 'with',\n",
       " 'chatbots',\n",
       " 'and',\n",
       " 'voicedriven',\n",
       " 'interfaces',\n",
       " 'expect',\n",
       " 'more',\n",
       " 'innovations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'space',\n",
       " 'as',\n",
       " 'brands',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'their',\n",
       " 'unique',\n",
       " 'conversationbased',\n",
       " 'solutions',\n",
       " 'Blackcoffer',\n",
       " 'Insights',\n",
       " '28',\n",
       " 'Samyak',\n",
       " 'Jain']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = content.split()\n",
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d896eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04a69e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8193f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1857253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/ai-tool-alexa...</td>\n",
       "      <td>How machine learning used in finance and banking?</td>\n",
       "      <td>Through AI tools like natural language proces...</td>\n",
       "      <td>Through AI tools like natural language process...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176131</td>\n",
       "      <td>0.531168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/ai-tool-alexa...   \n",
       "\n",
       "                                               title  \\\n",
       "0  How machine learning used in finance and banking?   \n",
       "\n",
       "                                             content  \\\n",
       "0   Through AI tools like natural language proces...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  Through AI tools like natural language process...              28   \n",
       "\n",
       "   Negative_Score  polarity  subjectivity  \n",
       "0               1  0.176131      0.531168  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "\n",
    "# Adding Subjectivity & Polarity\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2418f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word average = 2746.0\n",
      "FOG INDEX =  206.76\n",
      "Average no of words per sentence\n",
      "504.0\n",
      "Complex Words 1003\n"
     ]
    }
   ],
   "source": [
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=print(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b105414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count 3246\n",
      "Percentage of Complex Words 30.899568699938385\n",
      "Average Word per Length 5.448412698412699\n",
      "The AVG number of syllables in the word is: \n",
      "2.2023809523809526\n"
     ]
    }
   ],
   "source": [
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8829c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "1\n",
      "Word average = 2746.0\n",
      "FOG INDEX =  206.76\n",
      "Average no of words per sentence\n",
      "504.0\n",
      "Complex Words 1003\n",
      "Word Count 3246\n",
      "Percentage of Complex Words 30.899568699938385\n",
      "Average Word per Length 5.448412698412699\n",
      "The AVG number of syllables in the word is: \n",
      "2.2023809523809526\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Word</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORDS</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>syllable</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/ai-tool-alexa...</td>\n",
       "      <td>How machine learning used in finance and banking?</td>\n",
       "      <td>Through AI tools like natural language proces...</td>\n",
       "      <td>Through AI tools like natural language process...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>30.899569</td>\n",
       "      <td>206.76</td>\n",
       "      <td>504.0</td>\n",
       "      <td>1003</td>\n",
       "      <td>3246</td>\n",
       "      <td>2.202381</td>\n",
       "      <td>5.448413</td>\n",
       "      <td>0.176131</td>\n",
       "      <td>0.531168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://insights.blackcoffer.com/ai-tool-alexa...   \n",
       "\n",
       "                                               title  \\\n",
       "0  How machine learning used in finance and banking?   \n",
       "\n",
       "                                             content  \\\n",
       "0   Through AI tools like natural language proces...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  Through AI tools like natural language process...              28   \n",
       "\n",
       "   Negative_Score  Avg_Sentence_Length  Percentage_Complex_Word  Fog_Index  \\\n",
       "0               1               2746.0                30.899569     206.76   \n",
       "\n",
       "    AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORDS  Word_Count  syllable  \\\n",
       "0                              504.0           1003        3246  2.202381   \n",
       "\n",
       "   Average_Word_Length  polarity  subjectivity  \n",
       "0             5.448413  0.176131      0.531168  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "# title\n",
    "\n",
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "# print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "# print(content)\n",
    "text = content.split()\n",
    "# print(text)\n",
    "len(text)\n",
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)\n",
    "\n",
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)\n",
    "\n",
    "\n",
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data\n",
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "print(AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n",
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "syllable = (syllable_count/len(content.split()))\n",
    "print(syllable)\n",
    "\n",
    "data = [[url,title,content,filter_content,Positive_score,Negative_score,AVG_SENTENCE_LENGTH,pcw,FOG_INDEX,\n",
    "         AVG_NUMBER_OF_WORDS_PER_SENTENCE,COMPLEX_WORDS,Word_Count,syllable,Average_Word_Length]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\",\"Avg_Sentence_Length\"\n",
    "                               ,\"Percentage_Complex_Word\",\"Fog_Index\",\" AVG_NUMBER_OF_WORDS_PER_SENTENCE\",\"COMPLEX_WORDS\",\n",
    "                               \"Word_Count\",\"syllable\",\"Average_Word_Length\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1442f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\Om Bhandwalkar\\Desktop\\BlackCoffer Assignment\\Output\\url_52.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbc3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
