{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b697d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human Rights Outlook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/human-rights-outlook/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046a707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Climate change, technological advances, and unprecedented levels of inequality could mean that global disruption becomes a norm in the coming decades. What is changing? Read on to discover what our robot, Athena, has found on the future of this topic and act accordingly for you, your family, and organization in the years ahead. Make notes on issues that could affect you and them as you go. If you are new to foresight, we recommend you view this slide presentation first to get the best out of this report Speed read Athena’s high-level take-outs on the left of each slide, or delve deeper into her findings on the right. Analysis For a more detailed explanation of the graphics used in this presentation please click here. All outlooks based on the time period 2020-2070 and what’s likely to be happening in 2025 at a 95% confidence level unless otherwise stated. Please contact us for longer-term outlooks. VIDEO SUMMARY To read more and for a video summary, click here \n",
      " Climate change technological advances and unprecedented levels of inequality could mean that global disruption becomes a norm in the coming decades What is changing Read on to discover what our robot Athena has found on the future of this topic and act accordingly for you your family and organization in the years ahead Make notes on issues that could affect you and them as you go If you are new to foresight we recommend you view this slide presentation first to get the best out of this report Speed read Athena’s highlevel takeouts on the left of each slide or delve deeper into her findings on the right Analysis For a more detailed explanation of the graphics used in this presentation please click here All outlooks based on the time period 20202070 and what’s likely to be happening in 2025 at a 95 confidence level unless otherwise stated Please contact us for longerterm outlooks VIDEO SUMMARY To read more and for a video summary click here \n",
      "['Climate', 'change', 'technological', 'advances', 'and', 'unprecedented', 'levels', 'of', 'inequality', 'could', 'mean', 'that', 'global', 'disruption', 'becomes', 'a', 'norm', 'in', 'the', 'coming', 'decades', 'What', 'is', 'changing', 'Read', 'on', 'to', 'discover', 'what', 'our', 'robot', 'Athena', 'has', 'found', 'on', 'the', 'future', 'of', 'this', 'topic', 'and', 'act', 'accordingly', 'for', 'you', 'your', 'family', 'and', 'organization', 'in', 'the', 'years', 'ahead', 'Make', 'notes', 'on', 'issues', 'that', 'could', 'affect', 'you', 'and', 'them', 'as', 'you', 'go', 'If', 'you', 'are', 'new', 'to', 'foresight', 'we', 'recommend', 'you', 'view', 'this', 'slide', 'presentation', 'first', 'to', 'get', 'the', 'best', 'out', 'of', 'this', 'report', 'Speed', 'read', 'Athena’s', 'highlevel', 'takeouts', 'on', 'the', 'left', 'of', 'each', 'slide', 'or', 'delve', 'deeper', 'into', 'her', 'findings', 'on', 'the', 'right', 'Analysis', 'For', 'a', 'more', 'detailed', 'explanation', 'of', 'the', 'graphics', 'used', 'in', 'this', 'presentation', 'please', 'click', 'here', 'All', 'outlooks', 'based', 'on', 'the', 'time', 'period', '20202070', 'and', 'what’s', 'likely', 'to', 'be', 'happening', 'in', '2025', 'at', 'a', '95', 'confidence', 'level', 'unless', 'otherwise', 'stated', 'Please', 'contact', 'us', 'for', 'longerterm', 'outlooks', 'VIDEO', 'SUMMARY', 'To', 'read', 'more', 'and', 'for', 'a', 'video', 'summary', 'click', 'here']\n"
     ]
    }
   ],
   "source": [
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "print(content)\n",
    "text = content.split()\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838db3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4eea9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcca2c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d323eef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/human-rights-...</td>\n",
       "      <td>Human Rights Outlook</td>\n",
       "      <td>Climate change technological advances and unp...</td>\n",
       "      <td>Climate change technological advances and unpr...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>0.468161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url                 title  \\\n",
       "0  https://insights.blackcoffer.com/human-rights-...  Human Rights Outlook   \n",
       "\n",
       "                                             content  \\\n",
       "0   Climate change technological advances and unp...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  Climate change technological advances and unpr...               5   \n",
       "\n",
       "   Negative_Score  polarity  subjectivity  \n",
       "0               3  0.258429      0.468161  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "\n",
    "# Adding Subjectivity & Polarity\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0822450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word average = 790.0\n",
      "FOG INDEX =  70.01\n",
      "Average no of words per sentence\n",
      "166.0\n",
      "Complex Words 278\n"
     ]
    }
   ],
   "source": [
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=print(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "398b9d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count 954\n",
      "Percentage of Complex Words 29.140461215932913\n",
      "Average Word per Length 4.759036144578313\n",
      "The AVG number of syllables in the word is: \n",
      "1.9578313253012047\n",
      "Word Count 954\n",
      "Percentage of Complex Words 29.140461215932913\n",
      "Average Word per Length 4.759036144578313\n",
      "The AVG number of syllables in the word is: \n",
      "1.9578313253012047\n"
     ]
    }
   ],
   "source": [
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "print(syllable_count/len(content.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3acdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "Word average = 790.0\n",
      "FOG INDEX =  70.01\n",
      "Average no of words per sentence\n",
      "166.0\n",
      "Complex Words 278\n",
      "Word Count 954\n",
      "Percentage of Complex Words 29.140461215932913\n",
      "Average Word per Length 4.759036144578313\n",
      "The AVG number of syllables in the word is: \n",
      "1.9578313253012047\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>filter_content</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Word</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORDS</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>syllable</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/human-rights-...</td>\n",
       "      <td>Human Rights Outlook</td>\n",
       "      <td>Climate change technological advances and unp...</td>\n",
       "      <td>Climate change technological advances and unpr...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>790.0</td>\n",
       "      <td>29.140461</td>\n",
       "      <td>70.01</td>\n",
       "      <td>166.0</td>\n",
       "      <td>278</td>\n",
       "      <td>954</td>\n",
       "      <td>1.957831</td>\n",
       "      <td>4.759036</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>0.468161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url                 title  \\\n",
       "0  https://insights.blackcoffer.com/human-rights-...  Human Rights Outlook   \n",
       "\n",
       "                                             content  \\\n",
       "0   Climate change technological advances and unp...   \n",
       "\n",
       "                                      filter_content  Positive_Score  \\\n",
       "0  Climate change technological advances and unpr...               5   \n",
       "\n",
       "   Negative_Score  Avg_Sentence_Length  Percentage_Complex_Word  Fog_Index  \\\n",
       "0               3                790.0                29.140461      70.01   \n",
       "\n",
       "    AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORDS  Word_Count  syllable  \\\n",
       "0                              166.0            278         954  1.957831   \n",
       "\n",
       "   Average_Word_Length  polarity  subjectivity  \n",
       "0             4.759036  0.258429      0.468161  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "url = \"\"\"https://insights.blackcoffer.com/human-rights-outlook/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "# title\n",
    "\n",
    "content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "content=content[0].text.replace('\\n',\" \")\n",
    "# print(content)\n",
    "#Punctuation\n",
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "# print(content)\n",
    "text = content.split()\n",
    "# print(text)\n",
    "len(text)\n",
    "#Positive Score \n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\positive-words.txt\") as pos:\n",
    "    poswords = pos.read().split(\"\\n\")  \n",
    "    poswords = poswords[5:]\n",
    "pos_count = \" \".join ([w for w in text if w in poswords])\n",
    "pos_count=pos_count.split(\" \")\n",
    "Positive_score=len(pos_count)\n",
    "print(Positive_score)\n",
    "\n",
    "#Negative Score\n",
    "with open(r\"C:\\Users\\Om Bhandwalkar\\Desktop\\pos\\negative-words.txt\",encoding =\"ISO-8859-1\") as neg:\n",
    "    negwords = neg.read().split(\"\\n\")\n",
    "    \n",
    "negwords = negwords[36:]\n",
    "neg_count = \" \".join ([w for w in text if w in negwords])\n",
    "neg_count=neg_count.split(\" \")\n",
    "Negative_score=len(neg_count)\n",
    "print(Negative_score)\n",
    "\n",
    "\n",
    "filter_content = ' '.join(text)\n",
    "data=[[url,title,content,filter_content,Positive_score,Negative_score]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data\n",
    "#AVG SENTENCE LENGTH\n",
    "AVG_SENTENCE_LENGTH = len(content.replace(' ',''))/len(re.split(r'[?!.]', content))\n",
    "print('Word average =', AVG_SENTENCE_LENGTH)\n",
    "import textstat\n",
    "#Fog index \n",
    "FOG_INDEX=(textstat.gunning_fog(content))\n",
    "print(\"FOG INDEX = \",FOG_INDEX)\n",
    "#Average No of Words Per Sentence \n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "print(\"Average no of words per sentence\")\n",
    "AVG_NUMBER_OF_WORDS_PER_SENTENCE=(sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE))\n",
    "print(AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "#Complex words\n",
    "def syllable_count(word):\n",
    "    count = 0\n",
    "    vowels = \"AEIOUYaeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)): \n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "            if word.endswith(\"es\"or \"ed\"):\n",
    "                count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "COMPLEX_WORDS=syllable_count(content)\n",
    "print(\"Complex Words\",COMPLEX_WORDS)\n",
    "#Word Count\n",
    "Word_Count=len(content)\n",
    "print(\"Word Count\",Word_Count)\n",
    "#Percentage Complex Words\n",
    "pcw=(COMPLEX_WORDS/Word_Count)*100\n",
    "print(\"Percentage of Complex Words\",pcw)\n",
    "#Average Word Length\n",
    "Average_Word_Length=len(content.replace(' ',''))/len(content.split())\n",
    "print(\"Average Word per Length\",Average_Word_Length)\n",
    "#Syllable Count Per Word\n",
    "word=content.replace(' ','')\n",
    "syllable_count=0\n",
    "for w in word:\n",
    "      if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "print(\"The AVG number of syllables in the word is: \")\n",
    "syllable = (syllable_count/len(content.split()))\n",
    "print(syllable)\n",
    "\n",
    "data = [[url,title,content,filter_content,Positive_score,Negative_score,AVG_SENTENCE_LENGTH,pcw,FOG_INDEX,\n",
    "         AVG_NUMBER_OF_WORDS_PER_SENTENCE,COMPLEX_WORDS,Word_Count,syllable,Average_Word_Length]]\n",
    "data=pd.DataFrame(data,columns=[\"url\",\"title\",\"content\",\"filter_content\",\"Positive_Score\",\"Negative_Score\",\"Avg_Sentence_Length\"\n",
    "                               ,\"Percentage_Complex_Word\",\"Fog_Index\",\" AVG_NUMBER_OF_WORDS_PER_SENTENCE\",\"COMPLEX_WORDS\",\n",
    "                               \"Word_Count\",\"syllable\",\"Average_Word_Length\"])\n",
    "from textblob import TextBlob\n",
    "# Get The Subjectivity\n",
    "def sentiment_analysis(data):\n",
    "    sentiment = TextBlob(data[\"content\"]).sentiment\n",
    "    return pd.Series([sentiment.polarity,sentiment.subjectivity ])\n",
    "data[[\"polarity\", \"subjectivity\"]] = data.apply(sentiment_analysis, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6833955",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\Om Bhandwalkar\\Desktop\\BlackCoffer Assignment\\Output\\url_91.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014cd82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
